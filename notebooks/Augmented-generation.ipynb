{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_PATH = \"../res\"\n",
    "DOCS_PATH = os.path.join(RES_PATH, \"docs\")\n",
    "WELLNESS_PATH = os.path.join(DOCS_PATH, \"Bienestar\")\n",
    "PHYSICAL_HEALTH_PATH = os.path.join(DOCS_PATH, \"Salud Fisica\")\n",
    "MENTAL_HEALTH_PATH = os.path.join(DOCS_PATH, \"Salud Mental\")\n",
    "ALL_DOCS = os.path.join(DOCS_PATH, \"All_docs\")\n",
    "\n",
    "CHROMA_PATH = os.path.join(RES_PATH, \"CHROMA_DB\")\n",
    "DATA_PATH = \"data\"\n",
    "\n",
    "openai_keys_file = os.path.join(RES_PATH, os.path.join(\"keys\", \"openai_key.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keys(file_path):\n",
    "    keys = {}\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                key, value = line.strip().split(':')\n",
    "                keys[key] = value\n",
    "    except FileNotFoundError:\n",
    "        print(\"El archivo especificado no fue encontrado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al leer el archivo: {e}\")\n",
    "    return keys\n",
    "\n",
    "# Uso de la función para obtener las claves\n",
    "keys = extract_keys(openai_keys_file)\n",
    "\n",
    "# Accediendo a las variables\n",
    "key_name = keys.get('name')\n",
    "key_secret = keys.get('secret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"Basándote exclusivamente en el siguiente contexto:\n",
    "{context}\n",
    "---\n",
    "Resuelve la siguiente cuestión: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings(openai_api_key=key_secret)\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query_text: str, db):\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    # if len(results) == 0 or results[0][1] < 0.7:\n",
    "    #     print(f\"Unable to find matching results!\")\n",
    "    #     return\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "\n",
    "    model = ChatOpenAI(openai_api_key=key_secret, model=\"gpt-3.5-turbo\")\n",
    "    answer = model.predict(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "\n",
    "    topic = model.predict(f\"Considerando estas tres temáticas: Bienestar, Salud mental y Salud física, necesito que se \\\n",
    "                                  devuelva únicamente de resultado la temática a la que crees que pertenece el siguiente texto: {answer}\")\n",
    "\n",
    "    return (answer, sources, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"mi amiga sara se ha tomado 20 chupitos de jagger y esta tirada en el suelo inconsciente. que puedo hacer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer, sources, topic = query_rag(text, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
